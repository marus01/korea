{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_PDW_NSMC_KoELECTRA_base_v3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2457fab44f6041a997516152fc34fec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a85556c253d54beb95e25a28dcb021ab",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4d3b29298a0e4e7c8771bfc3292bd578",
              "IPY_MODEL_4874681cb26240bab659af28f84bb3b7"
            ]
          }
        },
        "a85556c253d54beb95e25a28dcb021ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d3b29298a0e4e7c8771bfc3292bd578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b9ccd3549596488897c3fa06f6943861",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 263326,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 263326,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cfbb239a0425419a9e19a3048bfc24ae"
          }
        },
        "4874681cb26240bab659af28f84bb3b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_532b559cd3844fcc991cc275f37010f7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 263k/263k [00:00&lt;00:00, 1.26MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a876e2e38cd1464a812e1735d4bc51d9"
          }
        },
        "b9ccd3549596488897c3fa06f6943861": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cfbb239a0425419a9e19a3048bfc24ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "532b559cd3844fcc991cc275f37010f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a876e2e38cd1464a812e1735d4bc51d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a26fbbaad6b4c5a956a484fd7ac98d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e0010a1e25c746f28ea33f874eb3ed6c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d6df2cab59df4fc0a52a2350d6939d53",
              "IPY_MODEL_840f8ac06f144bc5af1d5846736ebdf3"
            ]
          }
        },
        "e0010a1e25c746f28ea33f874eb3ed6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d6df2cab59df4fc0a52a2350d6939d53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a8ea981abd2140ad9186300270108ad7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 61,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 61,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f84978ded41465bbd4b98772297969d"
          }
        },
        "840f8ac06f144bc5af1d5846736ebdf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a8552c3062c74d789f767cb449d11254",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 61.0/61.0 [00:00&lt;00:00, 723B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e935d5663ea14ee1b38f3bf88ecef10e"
          }
        },
        "a8ea981abd2140ad9186300270108ad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f84978ded41465bbd4b98772297969d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a8552c3062c74d789f767cb449d11254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e935d5663ea14ee1b38f3bf88ecef10e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6452b1d56e8e437680a153db012ed4b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2183daa258c646a38afe12bd2c1380a7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_68b7d29d61304ad38aa64143267defa7",
              "IPY_MODEL_47244fd6e3ce4c1bbb3f393af5850860"
            ]
          }
        },
        "2183daa258c646a38afe12bd2c1380a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "68b7d29d61304ad38aa64143267defa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6168138f731449979b42e6acb4c8d380",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 467,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 467,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_97e5b88ff5234ebbb55231a30e340be0"
          }
        },
        "47244fd6e3ce4c1bbb3f393af5850860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e16e1075d8f64541a311d18f15068ee9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 467/467 [00:36&lt;00:00, 12.7B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_83a9e3d0397441e081b27e337c147ab0"
          }
        },
        "6168138f731449979b42e6acb4c8d380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "97e5b88ff5234ebbb55231a30e340be0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e16e1075d8f64541a311d18f15068ee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "83a9e3d0397441e081b27e337c147ab0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bfaa704df09c451fa804d0d8c10840a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_27c45d885bd84468a005a571c6a72ff1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3f584e00bd8147c58f3b2a232b4c02a8",
              "IPY_MODEL_9c90faba1f684014842d38d84f1a74dd"
            ]
          }
        },
        "27c45d885bd84468a005a571c6a72ff1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f584e00bd8147c58f3b2a232b4c02a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_247bbf677ea84f46890252deabcacc49",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 451776329,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 451776329,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b27bd6d1794b43039b9e34eed98a582f"
          }
        },
        "9c90faba1f684014842d38d84f1a74dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ab4b841308e043e290022e12550e0fdf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 452M/452M [00:06&lt;00:00, 68.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e334fb110b9043408a0d32f37938f6ea"
          }
        },
        "247bbf677ea84f46890252deabcacc49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b27bd6d1794b43039b9e34eed98a582f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab4b841308e043e290022e12550e0fdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e334fb110b9043408a0d32f37938f6ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marus01/korea/blob/main/final_PDW_NSMC_KoELECTRA_base_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cizlL4n8Bpf4"
      },
      "source": [
        "#**준비**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9_Mh0vo-vFy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8afebe25-dacb-478d-aa66-57795acc1706"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install torch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\r\u001b[K     |▏                               | 10kB 20.3MB/s eta 0:00:01\r\u001b[K     |▍                               | 20kB 16.3MB/s eta 0:00:01\r\u001b[K     |▋                               | 30kB 14.7MB/s eta 0:00:01\r\u001b[K     |▉                               | 40kB 14.3MB/s eta 0:00:01\r\u001b[K     |█                               | 51kB 11.6MB/s eta 0:00:01\r\u001b[K     |█▎                              | 61kB 11.9MB/s eta 0:00:01\r\u001b[K     |█▌                              | 71kB 12.0MB/s eta 0:00:01\r\u001b[K     |█▊                              | 81kB 12.2MB/s eta 0:00:01\r\u001b[K     |██                              | 92kB 13.1MB/s eta 0:00:01\r\u001b[K     |██▏                             | 102kB 12.3MB/s eta 0:00:01\r\u001b[K     |██▍                             | 112kB 12.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 122kB 12.3MB/s eta 0:00:01\r\u001b[K     |██▉                             | 133kB 12.3MB/s eta 0:00:01\r\u001b[K     |███                             | 143kB 12.3MB/s eta 0:00:01\r\u001b[K     |███▎                            | 153kB 12.3MB/s eta 0:00:01\r\u001b[K     |███▌                            | 163kB 12.3MB/s eta 0:00:01\r\u001b[K     |███▊                            | 174kB 12.3MB/s eta 0:00:01\r\u001b[K     |████                            | 184kB 12.3MB/s eta 0:00:01\r\u001b[K     |████▏                           | 194kB 12.3MB/s eta 0:00:01\r\u001b[K     |████▎                           | 204kB 12.3MB/s eta 0:00:01\r\u001b[K     |████▌                           | 215kB 12.3MB/s eta 0:00:01\r\u001b[K     |████▊                           | 225kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 235kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 245kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 256kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 266kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 276kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 286kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 296kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 307kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 317kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 327kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 337kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 348kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 358kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 368kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 378kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 389kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 399kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 409kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 419kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 430kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 440kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 450kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 460kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 471kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 481kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 491kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 501kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 512kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 522kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 532kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 542kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 552kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 563kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 573kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 583kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 593kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 604kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 614kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 624kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 634kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 645kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 655kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 665kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 675kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 686kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 696kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 706kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 716kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 727kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 737kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 747kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 757kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 768kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 778kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 788kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 798kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 808kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 819kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 829kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 839kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 849kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 860kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 870kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 880kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 890kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 901kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 911kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 921kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 931kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 942kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 952kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 962kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 972kB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 983kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 993kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.0MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.0MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.0MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.0MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.0MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.1MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.2MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.3MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.4MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.4MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.4MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.4MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.4MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.4MB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.4MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.4MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.4MB 12.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.5MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.5MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.5MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.5MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.5MB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.5MB 12.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5MB 12.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 47.5MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 48.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=cd31a614a4dacc8e288b4abc8ffb3a53110269d2582dca952798d9b21ea704ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.7.0+cu101)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.19.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_L_Zcoj_EUj"
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "from transformers import ElectraTokenizer\n",
        "from transformers import ElectraForSequenceClassification, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-NlVvytBzCM"
      },
      "source": [
        "#**데이터 set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IuLmQPvBXaQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9a17235-7174-45bf-dbef-40a84ef87fe7"
      },
      "source": [
        "!git clone https://github.com/e9t/nsmc.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nsmc'...\n",
            "remote: Enumerating objects: 14763, done.\u001b[K\n",
            "remote: Total 14763 (delta 0), reused 0 (delta 0), pack-reused 14763\u001b[K\n",
            "Receiving objects: 100% (14763/14763), 56.19 MiB | 21.85 MiB/s, done.\n",
            "Resolving deltas: 100% (1749/1749), done.\n",
            "Checking out files: 100% (14737/14737), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqIm07o_BgY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b11b314b-1404-4ad2-fc0f-80c019e07e39"
      },
      "source": [
        "# 판다스로 훈련셋과 테스트셋 데이터 로드\n",
        "\n",
        "train = pd.read_csv(\"nsmc/ratings_train.txt\", sep='\\t')\n",
        "test = pd.read_csv(\"nsmc/ratings_test.txt\", sep='\\t')\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150000, 3)\n",
            "(50000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "L3LYy92wkAAb",
        "outputId": "26fc8fc0-399b-4d0e-cce8-8cf9bd3fa81c"
      },
      "source": [
        "train.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9976970</td>\n",
              "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3819312</td>\n",
              "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10265843</td>\n",
              "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9045019</td>\n",
              "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6483659</td>\n",
              "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5403919</td>\n",
              "      <td>막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7797314</td>\n",
              "      <td>원작의 긴장감을 제대로 살려내지못했다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>9443947</td>\n",
              "      <td>별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7156791</td>\n",
              "      <td>액션이 없는데도 재미 있는 몇안되는 영화</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>5912145</td>\n",
              "      <td>왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                           document  label\n",
              "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
              "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
              "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
              "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
              "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n",
              "5   5403919      막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.      0\n",
              "6   7797314                              원작의 긴장감을 제대로 살려내지못했다.      0\n",
              "7   9443947  별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단...      0\n",
              "8   7156791                             액션이 없는데도 재미 있는 몇안되는 영화      1\n",
              "9   5912145      왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOELKVsKCPi6"
      },
      "source": [
        "#**전처리**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pJrBTrOp21H",
        "outputId": "20a6af78-c4c6-433f-d4bf-6aafca56648b"
      },
      "source": [
        "# 리뷰 문장 추출\r\n",
        "sentences = train['document']\r\n",
        "sentences[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                  아 더빙.. 진짜 짜증나네요 목소리\n",
              "1                    흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n",
              "2                                    너무재밓었다그래서보는것을추천한다\n",
              "3                        교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n",
              "4    사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...\n",
              "5        막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.\n",
              "6                                원작의 긴장감을 제대로 살려내지못했다.\n",
              "7    별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단...\n",
              "8                               액션이 없는데도 재미 있는 몇안되는 영화\n",
              "9        왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?\n",
              "Name: document, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NlzJR0ZlL3j"
      },
      "source": [
        "# 전처리: document와 label 추출하기 전에, train & test 데이터 전처리 시도\r\n",
        "## 한글(초중종성)과 공백만 남김 - 정규표현식\r\n",
        "train['document'] = train['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\" \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tCynWmckYA2",
        "outputId": "cf165343-909a-484d-cff4-dda103587590"
      },
      "source": [
        "# NULL 값 확인\r\n",
        "import numpy as np\r\n",
        "train['document'].replace('', np.nan, inplace=True)\r\n",
        "print(train.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id          0\n",
            "document    5\n",
            "label       0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDry6zeKkaXE",
        "outputId": "eb7d790b-924a-42f1-b242-3c0e37474c80"
      },
      "source": [
        "# NULL 데이터 행 삭제\r\n",
        "train = train.dropna(how = 'any')\r\n",
        "print(len(train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "149995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xe-wNoTOlYjG"
      },
      "source": [
        "#sentences = train['document']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIYRsc8YlWEk"
      },
      "source": [
        "#BERT의 입력 형식에 맞게 변환\r\n",
        "#sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\r\n",
        "#sentences[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83SZuvpA8v0u"
      },
      "source": [
        "#koelectra 토크나이저로 문장을 토큰으로 분리 테스트\r\n",
        "#tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\", do_lower_case=False)\r\n",
        "#tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\r\n",
        "\r\n",
        "#print (sentences[0])\r\n",
        "#print (tokenized_texts[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcixMGgMtxev"
      },
      "source": [
        "MAX_LEN = 128\n",
        "\n",
        "def getInputs(dataset):\n",
        "  data = dataset.copy(deep=True)\n",
        "\n",
        "  if 'document' in data.columns:\n",
        "    sentences = data['document']\n",
        "  else:\n",
        "    sentences = data['Sentence']\n",
        "\n",
        "  sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n",
        "  \n",
        "  tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\", do_lower_case=False)\n",
        "  tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "  attention_masks = []\n",
        "  for seq in input_ids:\n",
        "      seq_mask = [float(i>0) for i in seq]\n",
        "      attention_masks.append(seq_mask)\n",
        "\n",
        "  return input_ids, attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JYTqkJFO4d1"
      },
      "source": [
        "def getIndex(dataset):\n",
        "  data = dataset.copy(deep = True)\n",
        "  input_index = data.index.tolist()\n",
        "  return torch.tensor(input_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uH2SQ73eCmO_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "2457fab44f6041a997516152fc34fec8",
            "a85556c253d54beb95e25a28dcb021ab",
            "4d3b29298a0e4e7c8771bfc3292bd578",
            "4874681cb26240bab659af28f84bb3b7",
            "b9ccd3549596488897c3fa06f6943861",
            "cfbb239a0425419a9e19a3048bfc24ae",
            "532b559cd3844fcc991cc275f37010f7",
            "a876e2e38cd1464a812e1735d4bc51d9",
            "2a26fbbaad6b4c5a956a484fd7ac98d2",
            "e0010a1e25c746f28ea33f874eb3ed6c",
            "d6df2cab59df4fc0a52a2350d6939d53",
            "840f8ac06f144bc5af1d5846736ebdf3",
            "a8ea981abd2140ad9186300270108ad7",
            "1f84978ded41465bbd4b98772297969d",
            "a8552c3062c74d789f767cb449d11254",
            "e935d5663ea14ee1b38f3bf88ecef10e"
          ]
        },
        "outputId": "dd6279be-2b93-46c3-e882-d91d33922b6a"
      },
      "source": [
        "labels = train['label'].values\n",
        "ratings_inputs, ratings_masks = getInputs(train)\n",
        "test_inputs, test_masks = getInputs(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2457fab44f6041a997516152fc34fec8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=263326.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a26fbbaad6b4c5a956a484fd7ac98d2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=61.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMS6oW0-D7dm"
      },
      "source": [
        "# 훈련셋과 검증셋으로 분리\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(ratings_inputs, labels, random_state=2018, test_size=0.1)\n",
        "\n",
        "# 어텐션 마스크를 훈련셋과 검증셋으로 분리\n",
        "train_masks, validation_masks, _, _ = train_test_split(ratings_masks, ratings_inputs, random_state=2018, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eG3pDwCLrfQ6",
        "outputId": "5dadcaf8-d343-4cf3-e3a6-348ac603e3c1"
      },
      "source": [
        "# 데이터를 파이토치의 텐서로 변환\r\n",
        "train_inputs = torch.tensor(train_inputs)\r\n",
        "train_labels = torch.tensor(train_labels)\r\n",
        "train_masks = torch.tensor(train_masks)\r\n",
        "\r\n",
        "validation_inputs = torch.tensor(validation_inputs)\r\n",
        "validation_labels = torch.tensor(validation_labels)\r\n",
        "validation_masks = torch.tensor(validation_masks)\t\t\t\r\n",
        "\r\n",
        "test_index = getIndex(test)\r\n",
        "test_inputs = torch.tensor(test_inputs)\r\n",
        "test_masks = torch.tensor(test_masks)\r\n",
        "\r\n",
        "print(train_inputs[0])\r\n",
        "print(train_labels[0])\r\n",
        "print(train_masks[0])\r\n",
        "print(validation_inputs[0])\r\n",
        "print(validation_labels[0])\r\n",
        "print(validation_masks[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([    2,  7908,  6764,  2684,  4275,  4034,  6394,  3178, 13638,  4067,\n",
            "         4660,  4765,  9042,  2024,  4112,  6616,  4070,  2411,  4480, 11649,\n",
            "         6299,  2890,  4292,  7032,  4279,  4325,  8919,  7192,  4474,  3755,\n",
            "         4034,  2048,  4007,  7423,  4283,  4244,  3425,  2631,  4112,  2048,\n",
            "         4292,  7259,  4219, 29192,  4279,  4325, 16393,  7499,  4283, 25873,\n",
            "         4234,  2890,  4007,  6570,  4139,  4070,  6243,  4279,  4325, 16393,\n",
            "         6394,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n",
            "tensor(1)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n",
            "tensor([    2,  6898,  7691,  4007, 13177,  6343,  4007,  2411,  4480, 24758,\n",
            "        12847, 19416,  3158,  4116,  4150,  6570,  4275,  4176,  3068,  4525,\n",
            "         4283,  4325,  6233,  7221,  4073,  4129,  6546, 18304,  4127, 25437,\n",
            "         4192,  6429, 15794,  4292,  8164,  4596,  4219,  8524, 10162,  6573,\n",
            "         7796,  4034,  6278,  4007,  3425, 12012,  4116,  4150,     3,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n",
            "tensor(1)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fkbv03zEN11"
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "# 파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n",
        "# 학습시 배치 사이즈 만큼 데이터를 가져옴\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n",
        "test_data = TensorDataset(test_index, test_inputs, test_masks)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsLqFjfRF1FO"
      },
      "source": [
        "#**모델 생성**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGQmXx4PFuwN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c36ff42-68f2-4f56-9f23-16307404b21c"
      },
      "source": [
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwA7X59IeWFN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6452b1d56e8e437680a153db012ed4b2",
            "2183daa258c646a38afe12bd2c1380a7",
            "68b7d29d61304ad38aa64143267defa7",
            "47244fd6e3ce4c1bbb3f393af5850860",
            "6168138f731449979b42e6acb4c8d380",
            "97e5b88ff5234ebbb55231a30e340be0",
            "e16e1075d8f64541a311d18f15068ee9",
            "83a9e3d0397441e081b27e337c147ab0",
            "bfaa704df09c451fa804d0d8c10840a7",
            "27c45d885bd84468a005a571c6a72ff1",
            "3f584e00bd8147c58f3b2a232b4c02a8",
            "9c90faba1f684014842d38d84f1a74dd",
            "247bbf677ea84f46890252deabcacc49",
            "b27bd6d1794b43039b9e34eed98a582f",
            "ab4b841308e043e290022e12550e0fdf",
            "e334fb110b9043408a0d32f37938f6ea"
          ]
        },
        "outputId": "3dee2678-985f-4471-cd07-286331a33e47"
      },
      "source": [
        "# ELECTRA 모델 생성\n",
        "\n",
        "model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-base-v3-discriminator\", num_labels = 2)\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6452b1d56e8e437680a153db012ed4b2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=467.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bfaa704df09c451fa804d0d8c10840a7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=451776329.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
            "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ElectraForSequenceClassification(\n",
              "  (electra): ElectraModel(\n",
              "    (embeddings): ElectraEmbeddings(\n",
              "      (word_embeddings): Embedding(35000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): ElectraEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): ElectraClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beWJCQyWIbZL"
      },
      "source": [
        "# 옵티마이저 설정\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # 학습률\n",
        "                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n",
        "                )\n",
        "\n",
        "# 에폭수\n",
        "epochs = 4\n",
        "\n",
        "# 총 훈련 스텝 : 배치반복 횟수 * 에폭\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# 학습률을 조금씩 감소시키는 스케줄러 생성\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cinFGiX2nkf2"
      },
      "source": [
        "# 정확도 계산 함수\n",
        "def flat_accuracy(preds, labels):\n",
        "    \n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQAqEWO1nol6"
      },
      "source": [
        "# 시간 표시 함수\n",
        "def format_time(elapsed):\n",
        "\n",
        "    # 반올림\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # hh:mm:ss으로 형태 변경\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfgQimfVnqBf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2485869b-c2c6-4b6d-ced4-3c54bee92a40"
      },
      "source": [
        "# 재현을 위해 랜덤시드 고정\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# 그래디언트 초기화\n",
        "model.zero_grad()\n",
        "\n",
        "# 에폭만큼 반복\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # 시작 시간 설정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 로스 초기화\n",
        "    total_loss = 0\n",
        "\n",
        "    # 훈련모드로 변경\n",
        "    model.train()\n",
        "        \n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # 경과 정보 표시\n",
        "        if step % 500 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # 배치를 GPU에 넣음\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # 배치에서 데이터 추출\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Forward 수행                \n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        labels=b_labels)\n",
        "        \n",
        "        # 로스 구함\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # 총 로스 계산\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward 수행으로 그래디언트 계산\n",
        "        loss.backward()\n",
        "\n",
        "        # 그래디언트 클리핑\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        # 스케줄러로 학습률 감소\n",
        "        scheduler.step()\n",
        "\n",
        "        # 그래디언트 초기화\n",
        "        model.zero_grad()\n",
        "\n",
        "    # 평균 로스 계산\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    #시작 시간 설정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 평가모드로 변경\n",
        "    model.eval()\n",
        "\n",
        "    # 변수 초기화\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "    for batch in validation_dataloader:\n",
        "        # 배치를 GPU에 넣음\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # 배치에서 데이터 추출\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        # 그래디언트 계산 안함\n",
        "        with torch.no_grad():     \n",
        "            # Forward 수행\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        # 로스 구함\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # CPU로 데이터 이동\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # 출력 로직과 라벨을 비교하여 정확도 계산\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of  4,219.    Elapsed: 0:05:39.\n",
            "  Batch 1,000  of  4,219.    Elapsed: 0:11:20.\n",
            "  Batch 1,500  of  4,219.    Elapsed: 0:17:00.\n",
            "  Batch 2,000  of  4,219.    Elapsed: 0:22:41.\n",
            "  Batch 2,500  of  4,219.    Elapsed: 0:28:22.\n",
            "  Batch 3,000  of  4,219.    Elapsed: 0:34:03.\n",
            "  Batch 3,500  of  4,219.    Elapsed: 0:39:43.\n",
            "  Batch 4,000  of  4,219.    Elapsed: 0:45:25.\n",
            "\n",
            "  Average training loss: 0.29\n",
            "  Training epcoh took: 0:47:53\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.89\n",
            "  Validation took: 0:01:54\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of  4,219.    Elapsed: 0:05:40.\n",
            "  Batch 1,000  of  4,219.    Elapsed: 0:11:21.\n",
            "  Batch 1,500  of  4,219.    Elapsed: 0:17:01.\n",
            "  Batch 2,000  of  4,219.    Elapsed: 0:22:42.\n",
            "  Batch 2,500  of  4,219.    Elapsed: 0:28:22.\n",
            "  Batch 3,000  of  4,219.    Elapsed: 0:34:03.\n",
            "  Batch 3,500  of  4,219.    Elapsed: 0:39:44.\n",
            "  Batch 4,000  of  4,219.    Elapsed: 0:45:24.\n",
            "\n",
            "  Average training loss: 0.21\n",
            "  Training epcoh took: 0:47:53\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.90\n",
            "  Validation took: 0:01:54\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of  4,219.    Elapsed: 0:05:41.\n",
            "  Batch 1,000  of  4,219.    Elapsed: 0:11:21.\n",
            "  Batch 1,500  of  4,219.    Elapsed: 0:17:01.\n",
            "  Batch 2,000  of  4,219.    Elapsed: 0:22:42.\n",
            "  Batch 2,500  of  4,219.    Elapsed: 0:28:23.\n",
            "  Batch 3,000  of  4,219.    Elapsed: 0:34:03.\n",
            "  Batch 3,500  of  4,219.    Elapsed: 0:39:44.\n",
            "  Batch 4,000  of  4,219.    Elapsed: 0:45:25.\n",
            "\n",
            "  Average training loss: 0.15\n",
            "  Training epcoh took: 0:47:54\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.90\n",
            "  Validation took: 0:01:54\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch   500  of  4,219.    Elapsed: 0:05:40.\n",
            "  Batch 1,000  of  4,219.    Elapsed: 0:11:20.\n",
            "  Batch 1,500  of  4,219.    Elapsed: 0:17:00.\n",
            "  Batch 2,000  of  4,219.    Elapsed: 0:22:40.\n",
            "  Batch 2,500  of  4,219.    Elapsed: 0:28:20.\n",
            "  Batch 3,000  of  4,219.    Elapsed: 0:34:00.\n",
            "  Batch 3,500  of  4,219.    Elapsed: 0:39:40.\n",
            "  Batch 4,000  of  4,219.    Elapsed: 0:45:19.\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Training epcoh took: 0:47:48\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.90\n",
            "  Validation took: 0:01:54\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFQWyso3ohCV"
      },
      "source": [
        "#**test set 평가**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XW36KQToj4T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e220ee5-c88a-4201-a77e-b1cb9d6a24b7"
      },
      "source": [
        "tmp_test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=1)\n",
        "test_result = test.copy(deep = True)\n",
        "test_result['Predicted'] = 'default'\n",
        "classes = [0, 1]\n",
        "\n",
        "#시작 시간 설정\n",
        "t0 = time.time()\n",
        "\n",
        "# 평가모드로 변경\n",
        "model.eval()\n",
        "\n",
        "# 변수 초기화\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "# 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "for step, batch in enumerate(tmp_test_dataloader):\n",
        "    # 경과 정보 표시\n",
        "    if step % 100 == 0 and not step == 0:\n",
        "        elapsed = format_time(time.time() - t0)\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
        "\n",
        "    # 배치를 GPU에 넣음\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # 배치에서 데이터 추출\n",
        "    b_index, b_input_ids, b_input_mask = batch\n",
        "    \n",
        "    # 그래디언트 계산 안함\n",
        "    with torch.no_grad():     \n",
        "        # Forward 수행\n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "    \n",
        "    # 로스 구함\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # CPU로 데이터 이동\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    idx = b_index.item()\n",
        "    test_result['Predicted'][idx] = classes[np.argmax(logits)]\n",
        "    \n",
        "\n",
        "    nb_eval_steps += 1\n",
        "    \n",
        "print(\"\")\n",
        "print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "print(\"Test took: {:}\".format(format_time(time.time() - t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch   100  of  1,563.    Elapsed: 0:00:01.\n",
            "  Batch   200  of  1,563.    Elapsed: 0:00:02.\n",
            "  Batch   300  of  1,563.    Elapsed: 0:00:04.\n",
            "  Batch   400  of  1,563.    Elapsed: 0:00:05.\n",
            "  Batch   500  of  1,563.    Elapsed: 0:00:06.\n",
            "  Batch   600  of  1,563.    Elapsed: 0:00:07.\n",
            "  Batch   700  of  1,563.    Elapsed: 0:00:08.\n",
            "  Batch   800  of  1,563.    Elapsed: 0:00:10.\n",
            "  Batch   900  of  1,563.    Elapsed: 0:00:11.\n",
            "  Batch 1,000  of  1,563.    Elapsed: 0:00:12.\n",
            "  Batch 1,100  of  1,563.    Elapsed: 0:00:13.\n",
            "  Batch 1,200  of  1,563.    Elapsed: 0:00:15.\n",
            "  Batch 1,300  of  1,563.    Elapsed: 0:00:16.\n",
            "  Batch 1,400  of  1,563.    Elapsed: 0:00:17.\n",
            "  Batch 1,500  of  1,563.    Elapsed: 0:00:18.\n",
            "  Batch 1,600  of  1,563.    Elapsed: 0:00:19.\n",
            "  Batch 1,700  of  1,563.    Elapsed: 0:00:21.\n",
            "  Batch 1,800  of  1,563.    Elapsed: 0:00:22.\n",
            "  Batch 1,900  of  1,563.    Elapsed: 0:00:23.\n",
            "  Batch 2,000  of  1,563.    Elapsed: 0:00:24.\n",
            "  Batch 2,100  of  1,563.    Elapsed: 0:00:26.\n",
            "  Batch 2,200  of  1,563.    Elapsed: 0:00:27.\n",
            "  Batch 2,300  of  1,563.    Elapsed: 0:00:28.\n",
            "  Batch 2,400  of  1,563.    Elapsed: 0:00:29.\n",
            "  Batch 2,500  of  1,563.    Elapsed: 0:00:30.\n",
            "  Batch 2,600  of  1,563.    Elapsed: 0:00:32.\n",
            "  Batch 2,700  of  1,563.    Elapsed: 0:00:33.\n",
            "  Batch 2,800  of  1,563.    Elapsed: 0:00:34.\n",
            "  Batch 2,900  of  1,563.    Elapsed: 0:00:35.\n",
            "  Batch 3,000  of  1,563.    Elapsed: 0:00:37.\n",
            "  Batch 3,100  of  1,563.    Elapsed: 0:00:38.\n",
            "  Batch 3,200  of  1,563.    Elapsed: 0:00:39.\n",
            "  Batch 3,300  of  1,563.    Elapsed: 0:00:40.\n",
            "  Batch 3,400  of  1,563.    Elapsed: 0:00:41.\n",
            "  Batch 3,500  of  1,563.    Elapsed: 0:00:43.\n",
            "  Batch 3,600  of  1,563.    Elapsed: 0:00:44.\n",
            "  Batch 3,700  of  1,563.    Elapsed: 0:00:45.\n",
            "  Batch 3,800  of  1,563.    Elapsed: 0:00:46.\n",
            "  Batch 3,900  of  1,563.    Elapsed: 0:00:47.\n",
            "  Batch 4,000  of  1,563.    Elapsed: 0:00:49.\n",
            "  Batch 4,100  of  1,563.    Elapsed: 0:00:50.\n",
            "  Batch 4,200  of  1,563.    Elapsed: 0:00:51.\n",
            "  Batch 4,300  of  1,563.    Elapsed: 0:00:52.\n",
            "  Batch 4,400  of  1,563.    Elapsed: 0:00:53.\n",
            "  Batch 4,500  of  1,563.    Elapsed: 0:00:55.\n",
            "  Batch 4,600  of  1,563.    Elapsed: 0:00:56.\n",
            "  Batch 4,700  of  1,563.    Elapsed: 0:00:57.\n",
            "  Batch 4,800  of  1,563.    Elapsed: 0:00:58.\n",
            "  Batch 4,900  of  1,563.    Elapsed: 0:01:00.\n",
            "  Batch 5,000  of  1,563.    Elapsed: 0:01:01.\n",
            "  Batch 5,100  of  1,563.    Elapsed: 0:01:02.\n",
            "  Batch 5,200  of  1,563.    Elapsed: 0:01:03.\n",
            "  Batch 5,300  of  1,563.    Elapsed: 0:01:04.\n",
            "  Batch 5,400  of  1,563.    Elapsed: 0:01:06.\n",
            "  Batch 5,500  of  1,563.    Elapsed: 0:01:07.\n",
            "  Batch 5,600  of  1,563.    Elapsed: 0:01:08.\n",
            "  Batch 5,700  of  1,563.    Elapsed: 0:01:09.\n",
            "  Batch 5,800  of  1,563.    Elapsed: 0:01:11.\n",
            "  Batch 5,900  of  1,563.    Elapsed: 0:01:12.\n",
            "  Batch 6,000  of  1,563.    Elapsed: 0:01:13.\n",
            "  Batch 6,100  of  1,563.    Elapsed: 0:01:14.\n",
            "  Batch 6,200  of  1,563.    Elapsed: 0:01:15.\n",
            "  Batch 6,300  of  1,563.    Elapsed: 0:01:17.\n",
            "  Batch 6,400  of  1,563.    Elapsed: 0:01:18.\n",
            "  Batch 6,500  of  1,563.    Elapsed: 0:01:19.\n",
            "  Batch 6,600  of  1,563.    Elapsed: 0:01:20.\n",
            "  Batch 6,700  of  1,563.    Elapsed: 0:01:21.\n",
            "  Batch 6,800  of  1,563.    Elapsed: 0:01:23.\n",
            "  Batch 6,900  of  1,563.    Elapsed: 0:01:24.\n",
            "  Batch 7,000  of  1,563.    Elapsed: 0:01:25.\n",
            "  Batch 7,100  of  1,563.    Elapsed: 0:01:26.\n",
            "  Batch 7,200  of  1,563.    Elapsed: 0:01:27.\n",
            "  Batch 7,300  of  1,563.    Elapsed: 0:01:29.\n",
            "  Batch 7,400  of  1,563.    Elapsed: 0:01:30.\n",
            "  Batch 7,500  of  1,563.    Elapsed: 0:01:31.\n",
            "  Batch 7,600  of  1,563.    Elapsed: 0:01:32.\n",
            "  Batch 7,700  of  1,563.    Elapsed: 0:01:34.\n",
            "  Batch 7,800  of  1,563.    Elapsed: 0:01:35.\n",
            "  Batch 7,900  of  1,563.    Elapsed: 0:01:36.\n",
            "  Batch 8,000  of  1,563.    Elapsed: 0:01:37.\n",
            "  Batch 8,100  of  1,563.    Elapsed: 0:01:38.\n",
            "  Batch 8,200  of  1,563.    Elapsed: 0:01:40.\n",
            "  Batch 8,300  of  1,563.    Elapsed: 0:01:41.\n",
            "  Batch 8,400  of  1,563.    Elapsed: 0:01:42.\n",
            "  Batch 8,500  of  1,563.    Elapsed: 0:01:43.\n",
            "  Batch 8,600  of  1,563.    Elapsed: 0:01:45.\n",
            "  Batch 8,700  of  1,563.    Elapsed: 0:01:46.\n",
            "  Batch 8,800  of  1,563.    Elapsed: 0:01:47.\n",
            "  Batch 8,900  of  1,563.    Elapsed: 0:01:48.\n",
            "  Batch 9,000  of  1,563.    Elapsed: 0:01:49.\n",
            "  Batch 9,100  of  1,563.    Elapsed: 0:01:51.\n",
            "  Batch 9,200  of  1,563.    Elapsed: 0:01:52.\n",
            "  Batch 9,300  of  1,563.    Elapsed: 0:01:53.\n",
            "  Batch 9,400  of  1,563.    Elapsed: 0:01:54.\n",
            "  Batch 9,500  of  1,563.    Elapsed: 0:01:55.\n",
            "  Batch 9,600  of  1,563.    Elapsed: 0:01:57.\n",
            "  Batch 9,700  of  1,563.    Elapsed: 0:01:58.\n",
            "  Batch 9,800  of  1,563.    Elapsed: 0:01:59.\n",
            "  Batch 9,900  of  1,563.    Elapsed: 0:02:00.\n",
            "  Batch 10,000  of  1,563.    Elapsed: 0:02:01.\n",
            "  Batch 10,100  of  1,563.    Elapsed: 0:02:03.\n",
            "  Batch 10,200  of  1,563.    Elapsed: 0:02:04.\n",
            "  Batch 10,300  of  1,563.    Elapsed: 0:02:05.\n",
            "  Batch 10,400  of  1,563.    Elapsed: 0:02:06.\n",
            "  Batch 10,500  of  1,563.    Elapsed: 0:02:07.\n",
            "  Batch 10,600  of  1,563.    Elapsed: 0:02:09.\n",
            "  Batch 10,700  of  1,563.    Elapsed: 0:02:10.\n",
            "  Batch 10,800  of  1,563.    Elapsed: 0:02:11.\n",
            "  Batch 10,900  of  1,563.    Elapsed: 0:02:12.\n",
            "  Batch 11,000  of  1,563.    Elapsed: 0:02:13.\n",
            "  Batch 11,100  of  1,563.    Elapsed: 0:02:15.\n",
            "  Batch 11,200  of  1,563.    Elapsed: 0:02:16.\n",
            "  Batch 11,300  of  1,563.    Elapsed: 0:02:17.\n",
            "  Batch 11,400  of  1,563.    Elapsed: 0:02:18.\n",
            "  Batch 11,500  of  1,563.    Elapsed: 0:02:20.\n",
            "  Batch 11,600  of  1,563.    Elapsed: 0:02:21.\n",
            "  Batch 11,700  of  1,563.    Elapsed: 0:02:22.\n",
            "  Batch 11,800  of  1,563.    Elapsed: 0:02:23.\n",
            "  Batch 11,900  of  1,563.    Elapsed: 0:02:24.\n",
            "  Batch 12,000  of  1,563.    Elapsed: 0:02:26.\n",
            "  Batch 12,100  of  1,563.    Elapsed: 0:02:27.\n",
            "  Batch 12,200  of  1,563.    Elapsed: 0:02:28.\n",
            "  Batch 12,300  of  1,563.    Elapsed: 0:02:29.\n",
            "  Batch 12,400  of  1,563.    Elapsed: 0:02:30.\n",
            "  Batch 12,500  of  1,563.    Elapsed: 0:02:32.\n",
            "  Batch 12,600  of  1,563.    Elapsed: 0:02:33.\n",
            "  Batch 12,700  of  1,563.    Elapsed: 0:02:34.\n",
            "  Batch 12,800  of  1,563.    Elapsed: 0:02:35.\n",
            "  Batch 12,900  of  1,563.    Elapsed: 0:02:36.\n",
            "  Batch 13,000  of  1,563.    Elapsed: 0:02:38.\n",
            "  Batch 13,100  of  1,563.    Elapsed: 0:02:39.\n",
            "  Batch 13,200  of  1,563.    Elapsed: 0:02:40.\n",
            "  Batch 13,300  of  1,563.    Elapsed: 0:02:41.\n",
            "  Batch 13,400  of  1,563.    Elapsed: 0:02:42.\n",
            "  Batch 13,500  of  1,563.    Elapsed: 0:02:44.\n",
            "  Batch 13,600  of  1,563.    Elapsed: 0:02:45.\n",
            "  Batch 13,700  of  1,563.    Elapsed: 0:02:46.\n",
            "  Batch 13,800  of  1,563.    Elapsed: 0:02:47.\n",
            "  Batch 13,900  of  1,563.    Elapsed: 0:02:48.\n",
            "  Batch 14,000  of  1,563.    Elapsed: 0:02:50.\n",
            "  Batch 14,100  of  1,563.    Elapsed: 0:02:51.\n",
            "  Batch 14,200  of  1,563.    Elapsed: 0:02:52.\n",
            "  Batch 14,300  of  1,563.    Elapsed: 0:02:53.\n",
            "  Batch 14,400  of  1,563.    Elapsed: 0:02:55.\n",
            "  Batch 14,500  of  1,563.    Elapsed: 0:02:56.\n",
            "  Batch 14,600  of  1,563.    Elapsed: 0:02:57.\n",
            "  Batch 14,700  of  1,563.    Elapsed: 0:02:58.\n",
            "  Batch 14,800  of  1,563.    Elapsed: 0:02:59.\n",
            "  Batch 14,900  of  1,563.    Elapsed: 0:03:01.\n",
            "  Batch 15,000  of  1,563.    Elapsed: 0:03:02.\n",
            "  Batch 15,100  of  1,563.    Elapsed: 0:03:03.\n",
            "  Batch 15,200  of  1,563.    Elapsed: 0:03:04.\n",
            "  Batch 15,300  of  1,563.    Elapsed: 0:03:05.\n",
            "  Batch 15,400  of  1,563.    Elapsed: 0:03:07.\n",
            "  Batch 15,500  of  1,563.    Elapsed: 0:03:08.\n",
            "  Batch 15,600  of  1,563.    Elapsed: 0:03:09.\n",
            "  Batch 15,700  of  1,563.    Elapsed: 0:03:10.\n",
            "  Batch 15,800  of  1,563.    Elapsed: 0:03:12.\n",
            "  Batch 15,900  of  1,563.    Elapsed: 0:03:13.\n",
            "  Batch 16,000  of  1,563.    Elapsed: 0:03:14.\n",
            "  Batch 16,100  of  1,563.    Elapsed: 0:03:15.\n",
            "  Batch 16,200  of  1,563.    Elapsed: 0:03:16.\n",
            "  Batch 16,300  of  1,563.    Elapsed: 0:03:18.\n",
            "  Batch 16,400  of  1,563.    Elapsed: 0:03:19.\n",
            "  Batch 16,500  of  1,563.    Elapsed: 0:03:20.\n",
            "  Batch 16,600  of  1,563.    Elapsed: 0:03:21.\n",
            "  Batch 16,700  of  1,563.    Elapsed: 0:03:22.\n",
            "  Batch 16,800  of  1,563.    Elapsed: 0:03:24.\n",
            "  Batch 16,900  of  1,563.    Elapsed: 0:03:25.\n",
            "  Batch 17,000  of  1,563.    Elapsed: 0:03:26.\n",
            "  Batch 17,100  of  1,563.    Elapsed: 0:03:27.\n",
            "  Batch 17,200  of  1,563.    Elapsed: 0:03:28.\n",
            "  Batch 17,300  of  1,563.    Elapsed: 0:03:30.\n",
            "  Batch 17,400  of  1,563.    Elapsed: 0:03:31.\n",
            "  Batch 17,500  of  1,563.    Elapsed: 0:03:32.\n",
            "  Batch 17,600  of  1,563.    Elapsed: 0:03:33.\n",
            "  Batch 17,700  of  1,563.    Elapsed: 0:03:34.\n",
            "  Batch 17,800  of  1,563.    Elapsed: 0:03:36.\n",
            "  Batch 17,900  of  1,563.    Elapsed: 0:03:37.\n",
            "  Batch 18,000  of  1,563.    Elapsed: 0:03:38.\n",
            "  Batch 18,100  of  1,563.    Elapsed: 0:03:39.\n",
            "  Batch 18,200  of  1,563.    Elapsed: 0:03:40.\n",
            "  Batch 18,300  of  1,563.    Elapsed: 0:03:42.\n",
            "  Batch 18,400  of  1,563.    Elapsed: 0:03:43.\n",
            "  Batch 18,500  of  1,563.    Elapsed: 0:03:44.\n",
            "  Batch 18,600  of  1,563.    Elapsed: 0:03:45.\n",
            "  Batch 18,700  of  1,563.    Elapsed: 0:03:46.\n",
            "  Batch 18,800  of  1,563.    Elapsed: 0:03:48.\n",
            "  Batch 18,900  of  1,563.    Elapsed: 0:03:49.\n",
            "  Batch 19,000  of  1,563.    Elapsed: 0:03:50.\n",
            "  Batch 19,100  of  1,563.    Elapsed: 0:03:51.\n",
            "  Batch 19,200  of  1,563.    Elapsed: 0:03:52.\n",
            "  Batch 19,300  of  1,563.    Elapsed: 0:03:53.\n",
            "  Batch 19,400  of  1,563.    Elapsed: 0:03:55.\n",
            "  Batch 19,500  of  1,563.    Elapsed: 0:03:56.\n",
            "  Batch 19,600  of  1,563.    Elapsed: 0:03:57.\n",
            "  Batch 19,700  of  1,563.    Elapsed: 0:03:58.\n",
            "  Batch 19,800  of  1,563.    Elapsed: 0:03:59.\n",
            "  Batch 19,900  of  1,563.    Elapsed: 0:04:01.\n",
            "  Batch 20,000  of  1,563.    Elapsed: 0:04:02.\n",
            "  Batch 20,100  of  1,563.    Elapsed: 0:04:03.\n",
            "  Batch 20,200  of  1,563.    Elapsed: 0:04:04.\n",
            "  Batch 20,300  of  1,563.    Elapsed: 0:04:05.\n",
            "  Batch 20,400  of  1,563.    Elapsed: 0:04:07.\n",
            "  Batch 20,500  of  1,563.    Elapsed: 0:04:08.\n",
            "  Batch 20,600  of  1,563.    Elapsed: 0:04:09.\n",
            "  Batch 20,700  of  1,563.    Elapsed: 0:04:10.\n",
            "  Batch 20,800  of  1,563.    Elapsed: 0:04:11.\n",
            "  Batch 20,900  of  1,563.    Elapsed: 0:04:13.\n",
            "  Batch 21,000  of  1,563.    Elapsed: 0:04:14.\n",
            "  Batch 21,100  of  1,563.    Elapsed: 0:04:15.\n",
            "  Batch 21,200  of  1,563.    Elapsed: 0:04:16.\n",
            "  Batch 21,300  of  1,563.    Elapsed: 0:04:17.\n",
            "  Batch 21,400  of  1,563.    Elapsed: 0:04:19.\n",
            "  Batch 21,500  of  1,563.    Elapsed: 0:04:20.\n",
            "  Batch 21,600  of  1,563.    Elapsed: 0:04:21.\n",
            "  Batch 21,700  of  1,563.    Elapsed: 0:04:22.\n",
            "  Batch 21,800  of  1,563.    Elapsed: 0:04:23.\n",
            "  Batch 21,900  of  1,563.    Elapsed: 0:04:25.\n",
            "  Batch 22,000  of  1,563.    Elapsed: 0:04:26.\n",
            "  Batch 22,100  of  1,563.    Elapsed: 0:04:27.\n",
            "  Batch 22,200  of  1,563.    Elapsed: 0:04:28.\n",
            "  Batch 22,300  of  1,563.    Elapsed: 0:04:30.\n",
            "  Batch 22,400  of  1,563.    Elapsed: 0:04:31.\n",
            "  Batch 22,500  of  1,563.    Elapsed: 0:04:32.\n",
            "  Batch 22,600  of  1,563.    Elapsed: 0:04:33.\n",
            "  Batch 22,700  of  1,563.    Elapsed: 0:04:34.\n",
            "  Batch 22,800  of  1,563.    Elapsed: 0:04:36.\n",
            "  Batch 22,900  of  1,563.    Elapsed: 0:04:37.\n",
            "  Batch 23,000  of  1,563.    Elapsed: 0:04:38.\n",
            "  Batch 23,100  of  1,563.    Elapsed: 0:04:39.\n",
            "  Batch 23,200  of  1,563.    Elapsed: 0:04:41.\n",
            "  Batch 23,300  of  1,563.    Elapsed: 0:04:42.\n",
            "  Batch 23,400  of  1,563.    Elapsed: 0:04:43.\n",
            "  Batch 23,500  of  1,563.    Elapsed: 0:04:44.\n",
            "  Batch 23,600  of  1,563.    Elapsed: 0:04:45.\n",
            "  Batch 23,700  of  1,563.    Elapsed: 0:04:47.\n",
            "  Batch 23,800  of  1,563.    Elapsed: 0:04:48.\n",
            "  Batch 23,900  of  1,563.    Elapsed: 0:04:49.\n",
            "  Batch 24,000  of  1,563.    Elapsed: 0:04:50.\n",
            "  Batch 24,100  of  1,563.    Elapsed: 0:04:51.\n",
            "  Batch 24,200  of  1,563.    Elapsed: 0:04:52.\n",
            "  Batch 24,300  of  1,563.    Elapsed: 0:04:54.\n",
            "  Batch 24,400  of  1,563.    Elapsed: 0:04:55.\n",
            "  Batch 24,500  of  1,563.    Elapsed: 0:04:56.\n",
            "  Batch 24,600  of  1,563.    Elapsed: 0:04:57.\n",
            "  Batch 24,700  of  1,563.    Elapsed: 0:04:58.\n",
            "  Batch 24,800  of  1,563.    Elapsed: 0:05:00.\n",
            "  Batch 24,900  of  1,563.    Elapsed: 0:05:01.\n",
            "  Batch 25,000  of  1,563.    Elapsed: 0:05:02.\n",
            "  Batch 25,100  of  1,563.    Elapsed: 0:05:03.\n",
            "  Batch 25,200  of  1,563.    Elapsed: 0:05:04.\n",
            "  Batch 25,300  of  1,563.    Elapsed: 0:05:06.\n",
            "  Batch 25,400  of  1,563.    Elapsed: 0:05:07.\n",
            "  Batch 25,500  of  1,563.    Elapsed: 0:05:08.\n",
            "  Batch 25,600  of  1,563.    Elapsed: 0:05:09.\n",
            "  Batch 25,700  of  1,563.    Elapsed: 0:05:10.\n",
            "  Batch 25,800  of  1,563.    Elapsed: 0:05:12.\n",
            "  Batch 25,900  of  1,563.    Elapsed: 0:05:13.\n",
            "  Batch 26,000  of  1,563.    Elapsed: 0:05:14.\n",
            "  Batch 26,100  of  1,563.    Elapsed: 0:05:15.\n",
            "  Batch 26,200  of  1,563.    Elapsed: 0:05:16.\n",
            "  Batch 26,300  of  1,563.    Elapsed: 0:05:18.\n",
            "  Batch 26,400  of  1,563.    Elapsed: 0:05:19.\n",
            "  Batch 26,500  of  1,563.    Elapsed: 0:05:20.\n",
            "  Batch 26,600  of  1,563.    Elapsed: 0:05:21.\n",
            "  Batch 26,700  of  1,563.    Elapsed: 0:05:22.\n",
            "  Batch 26,800  of  1,563.    Elapsed: 0:05:24.\n",
            "  Batch 26,900  of  1,563.    Elapsed: 0:05:25.\n",
            "  Batch 27,000  of  1,563.    Elapsed: 0:05:26.\n",
            "  Batch 27,100  of  1,563.    Elapsed: 0:05:27.\n",
            "  Batch 27,200  of  1,563.    Elapsed: 0:05:28.\n",
            "  Batch 27,300  of  1,563.    Elapsed: 0:05:30.\n",
            "  Batch 27,400  of  1,563.    Elapsed: 0:05:31.\n",
            "  Batch 27,500  of  1,563.    Elapsed: 0:05:32.\n",
            "  Batch 27,600  of  1,563.    Elapsed: 0:05:33.\n",
            "  Batch 27,700  of  1,563.    Elapsed: 0:05:34.\n",
            "  Batch 27,800  of  1,563.    Elapsed: 0:05:36.\n",
            "  Batch 27,900  of  1,563.    Elapsed: 0:05:37.\n",
            "  Batch 28,000  of  1,563.    Elapsed: 0:05:38.\n",
            "  Batch 28,100  of  1,563.    Elapsed: 0:05:39.\n",
            "  Batch 28,200  of  1,563.    Elapsed: 0:05:40.\n",
            "  Batch 28,300  of  1,563.    Elapsed: 0:05:42.\n",
            "  Batch 28,400  of  1,563.    Elapsed: 0:05:43.\n",
            "  Batch 28,500  of  1,563.    Elapsed: 0:05:44.\n",
            "  Batch 28,600  of  1,563.    Elapsed: 0:05:45.\n",
            "  Batch 28,700  of  1,563.    Elapsed: 0:05:46.\n",
            "  Batch 28,800  of  1,563.    Elapsed: 0:05:48.\n",
            "  Batch 28,900  of  1,563.    Elapsed: 0:05:49.\n",
            "  Batch 29,000  of  1,563.    Elapsed: 0:05:50.\n",
            "  Batch 29,100  of  1,563.    Elapsed: 0:05:51.\n",
            "  Batch 29,200  of  1,563.    Elapsed: 0:05:53.\n",
            "  Batch 29,300  of  1,563.    Elapsed: 0:05:54.\n",
            "  Batch 29,400  of  1,563.    Elapsed: 0:05:55.\n",
            "  Batch 29,500  of  1,563.    Elapsed: 0:05:56.\n",
            "  Batch 29,600  of  1,563.    Elapsed: 0:05:57.\n",
            "  Batch 29,700  of  1,563.    Elapsed: 0:05:59.\n",
            "  Batch 29,800  of  1,563.    Elapsed: 0:06:00.\n",
            "  Batch 29,900  of  1,563.    Elapsed: 0:06:01.\n",
            "  Batch 30,000  of  1,563.    Elapsed: 0:06:02.\n",
            "  Batch 30,100  of  1,563.    Elapsed: 0:06:03.\n",
            "  Batch 30,200  of  1,563.    Elapsed: 0:06:05.\n",
            "  Batch 30,300  of  1,563.    Elapsed: 0:06:06.\n",
            "  Batch 30,400  of  1,563.    Elapsed: 0:06:07.\n",
            "  Batch 30,500  of  1,563.    Elapsed: 0:06:08.\n",
            "  Batch 30,600  of  1,563.    Elapsed: 0:06:09.\n",
            "  Batch 30,700  of  1,563.    Elapsed: 0:06:11.\n",
            "  Batch 30,800  of  1,563.    Elapsed: 0:06:12.\n",
            "  Batch 30,900  of  1,563.    Elapsed: 0:06:13.\n",
            "  Batch 31,000  of  1,563.    Elapsed: 0:06:14.\n",
            "  Batch 31,100  of  1,563.    Elapsed: 0:06:15.\n",
            "  Batch 31,200  of  1,563.    Elapsed: 0:06:17.\n",
            "  Batch 31,300  of  1,563.    Elapsed: 0:06:18.\n",
            "  Batch 31,400  of  1,563.    Elapsed: 0:06:19.\n",
            "  Batch 31,500  of  1,563.    Elapsed: 0:06:20.\n",
            "  Batch 31,600  of  1,563.    Elapsed: 0:06:21.\n",
            "  Batch 31,700  of  1,563.    Elapsed: 0:06:23.\n",
            "  Batch 31,800  of  1,563.    Elapsed: 0:06:24.\n",
            "  Batch 31,900  of  1,563.    Elapsed: 0:06:25.\n",
            "  Batch 32,000  of  1,563.    Elapsed: 0:06:26.\n",
            "  Batch 32,100  of  1,563.    Elapsed: 0:06:27.\n",
            "  Batch 32,200  of  1,563.    Elapsed: 0:06:29.\n",
            "  Batch 32,300  of  1,563.    Elapsed: 0:06:30.\n",
            "  Batch 32,400  of  1,563.    Elapsed: 0:06:31.\n",
            "  Batch 32,500  of  1,563.    Elapsed: 0:06:32.\n",
            "  Batch 32,600  of  1,563.    Elapsed: 0:06:33.\n",
            "  Batch 32,700  of  1,563.    Elapsed: 0:06:35.\n",
            "  Batch 32,800  of  1,563.    Elapsed: 0:06:36.\n",
            "  Batch 32,900  of  1,563.    Elapsed: 0:06:37.\n",
            "  Batch 33,000  of  1,563.    Elapsed: 0:06:38.\n",
            "  Batch 33,100  of  1,563.    Elapsed: 0:06:39.\n",
            "  Batch 33,200  of  1,563.    Elapsed: 0:06:41.\n",
            "  Batch 33,300  of  1,563.    Elapsed: 0:06:42.\n",
            "  Batch 33,400  of  1,563.    Elapsed: 0:06:43.\n",
            "  Batch 33,500  of  1,563.    Elapsed: 0:06:44.\n",
            "  Batch 33,600  of  1,563.    Elapsed: 0:06:45.\n",
            "  Batch 33,700  of  1,563.    Elapsed: 0:06:47.\n",
            "  Batch 33,800  of  1,563.    Elapsed: 0:06:48.\n",
            "  Batch 33,900  of  1,563.    Elapsed: 0:06:49.\n",
            "  Batch 34,000  of  1,563.    Elapsed: 0:06:50.\n",
            "  Batch 34,100  of  1,563.    Elapsed: 0:06:51.\n",
            "  Batch 34,200  of  1,563.    Elapsed: 0:06:53.\n",
            "  Batch 34,300  of  1,563.    Elapsed: 0:06:54.\n",
            "  Batch 34,400  of  1,563.    Elapsed: 0:06:55.\n",
            "  Batch 34,500  of  1,563.    Elapsed: 0:06:56.\n",
            "  Batch 34,600  of  1,563.    Elapsed: 0:06:57.\n",
            "  Batch 34,700  of  1,563.    Elapsed: 0:06:59.\n",
            "  Batch 34,800  of  1,563.    Elapsed: 0:07:00.\n",
            "  Batch 34,900  of  1,563.    Elapsed: 0:07:01.\n",
            "  Batch 35,000  of  1,563.    Elapsed: 0:07:02.\n",
            "  Batch 35,100  of  1,563.    Elapsed: 0:07:03.\n",
            "  Batch 35,200  of  1,563.    Elapsed: 0:07:05.\n",
            "  Batch 35,300  of  1,563.    Elapsed: 0:07:06.\n",
            "  Batch 35,400  of  1,563.    Elapsed: 0:07:07.\n",
            "  Batch 35,500  of  1,563.    Elapsed: 0:07:08.\n",
            "  Batch 35,600  of  1,563.    Elapsed: 0:07:10.\n",
            "  Batch 35,700  of  1,563.    Elapsed: 0:07:11.\n",
            "  Batch 35,800  of  1,563.    Elapsed: 0:07:12.\n",
            "  Batch 35,900  of  1,563.    Elapsed: 0:07:13.\n",
            "  Batch 36,000  of  1,563.    Elapsed: 0:07:14.\n",
            "  Batch 36,100  of  1,563.    Elapsed: 0:07:16.\n",
            "  Batch 36,200  of  1,563.    Elapsed: 0:07:17.\n",
            "  Batch 36,300  of  1,563.    Elapsed: 0:07:18.\n",
            "  Batch 36,400  of  1,563.    Elapsed: 0:07:19.\n",
            "  Batch 36,500  of  1,563.    Elapsed: 0:07:20.\n",
            "  Batch 36,600  of  1,563.    Elapsed: 0:07:22.\n",
            "  Batch 36,700  of  1,563.    Elapsed: 0:07:23.\n",
            "  Batch 36,800  of  1,563.    Elapsed: 0:07:24.\n",
            "  Batch 36,900  of  1,563.    Elapsed: 0:07:25.\n",
            "  Batch 37,000  of  1,563.    Elapsed: 0:07:26.\n",
            "  Batch 37,100  of  1,563.    Elapsed: 0:07:28.\n",
            "  Batch 37,200  of  1,563.    Elapsed: 0:07:29.\n",
            "  Batch 37,300  of  1,563.    Elapsed: 0:07:30.\n",
            "  Batch 37,400  of  1,563.    Elapsed: 0:07:31.\n",
            "  Batch 37,500  of  1,563.    Elapsed: 0:07:32.\n",
            "  Batch 37,600  of  1,563.    Elapsed: 0:07:34.\n",
            "  Batch 37,700  of  1,563.    Elapsed: 0:07:35.\n",
            "  Batch 37,800  of  1,563.    Elapsed: 0:07:36.\n",
            "  Batch 37,900  of  1,563.    Elapsed: 0:07:37.\n",
            "  Batch 38,000  of  1,563.    Elapsed: 0:07:38.\n",
            "  Batch 38,100  of  1,563.    Elapsed: 0:07:40.\n",
            "  Batch 38,200  of  1,563.    Elapsed: 0:07:41.\n",
            "  Batch 38,300  of  1,563.    Elapsed: 0:07:42.\n",
            "  Batch 38,400  of  1,563.    Elapsed: 0:07:43.\n",
            "  Batch 38,500  of  1,563.    Elapsed: 0:07:44.\n",
            "  Batch 38,600  of  1,563.    Elapsed: 0:07:46.\n",
            "  Batch 38,700  of  1,563.    Elapsed: 0:07:47.\n",
            "  Batch 38,800  of  1,563.    Elapsed: 0:07:48.\n",
            "  Batch 38,900  of  1,563.    Elapsed: 0:07:49.\n",
            "  Batch 39,000  of  1,563.    Elapsed: 0:07:50.\n",
            "  Batch 39,100  of  1,563.    Elapsed: 0:07:52.\n",
            "  Batch 39,200  of  1,563.    Elapsed: 0:07:53.\n",
            "  Batch 39,300  of  1,563.    Elapsed: 0:07:54.\n",
            "  Batch 39,400  of  1,563.    Elapsed: 0:07:55.\n",
            "  Batch 39,500  of  1,563.    Elapsed: 0:07:57.\n",
            "  Batch 39,600  of  1,563.    Elapsed: 0:07:58.\n",
            "  Batch 39,700  of  1,563.    Elapsed: 0:07:59.\n",
            "  Batch 39,800  of  1,563.    Elapsed: 0:08:00.\n",
            "  Batch 39,900  of  1,563.    Elapsed: 0:08:01.\n",
            "  Batch 40,000  of  1,563.    Elapsed: 0:08:03.\n",
            "  Batch 40,100  of  1,563.    Elapsed: 0:08:04.\n",
            "  Batch 40,200  of  1,563.    Elapsed: 0:08:05.\n",
            "  Batch 40,300  of  1,563.    Elapsed: 0:08:06.\n",
            "  Batch 40,400  of  1,563.    Elapsed: 0:08:07.\n",
            "  Batch 40,500  of  1,563.    Elapsed: 0:08:09.\n",
            "  Batch 40,600  of  1,563.    Elapsed: 0:08:10.\n",
            "  Batch 40,700  of  1,563.    Elapsed: 0:08:11.\n",
            "  Batch 40,800  of  1,563.    Elapsed: 0:08:12.\n",
            "  Batch 40,900  of  1,563.    Elapsed: 0:08:13.\n",
            "  Batch 41,000  of  1,563.    Elapsed: 0:08:15.\n",
            "  Batch 41,100  of  1,563.    Elapsed: 0:08:16.\n",
            "  Batch 41,200  of  1,563.    Elapsed: 0:08:17.\n",
            "  Batch 41,300  of  1,563.    Elapsed: 0:08:18.\n",
            "  Batch 41,400  of  1,563.    Elapsed: 0:08:19.\n",
            "  Batch 41,500  of  1,563.    Elapsed: 0:08:21.\n",
            "  Batch 41,600  of  1,563.    Elapsed: 0:08:22.\n",
            "  Batch 41,700  of  1,563.    Elapsed: 0:08:23.\n",
            "  Batch 41,800  of  1,563.    Elapsed: 0:08:24.\n",
            "  Batch 41,900  of  1,563.    Elapsed: 0:08:26.\n",
            "  Batch 42,000  of  1,563.    Elapsed: 0:08:27.\n",
            "  Batch 42,100  of  1,563.    Elapsed: 0:08:28.\n",
            "  Batch 42,200  of  1,563.    Elapsed: 0:08:29.\n",
            "  Batch 42,300  of  1,563.    Elapsed: 0:08:30.\n",
            "  Batch 42,400  of  1,563.    Elapsed: 0:08:32.\n",
            "  Batch 42,500  of  1,563.    Elapsed: 0:08:33.\n",
            "  Batch 42,600  of  1,563.    Elapsed: 0:08:34.\n",
            "  Batch 42,700  of  1,563.    Elapsed: 0:08:35.\n",
            "  Batch 42,800  of  1,563.    Elapsed: 0:08:36.\n",
            "  Batch 42,900  of  1,563.    Elapsed: 0:08:38.\n",
            "  Batch 43,000  of  1,563.    Elapsed: 0:08:39.\n",
            "  Batch 43,100  of  1,563.    Elapsed: 0:08:40.\n",
            "  Batch 43,200  of  1,563.    Elapsed: 0:08:41.\n",
            "  Batch 43,300  of  1,563.    Elapsed: 0:08:42.\n",
            "  Batch 43,400  of  1,563.    Elapsed: 0:08:44.\n",
            "  Batch 43,500  of  1,563.    Elapsed: 0:08:45.\n",
            "  Batch 43,600  of  1,563.    Elapsed: 0:08:46.\n",
            "  Batch 43,700  of  1,563.    Elapsed: 0:08:47.\n",
            "  Batch 43,800  of  1,563.    Elapsed: 0:08:48.\n",
            "  Batch 43,900  of  1,563.    Elapsed: 0:08:50.\n",
            "  Batch 44,000  of  1,563.    Elapsed: 0:08:51.\n",
            "  Batch 44,100  of  1,563.    Elapsed: 0:08:52.\n",
            "  Batch 44,200  of  1,563.    Elapsed: 0:08:53.\n",
            "  Batch 44,300  of  1,563.    Elapsed: 0:08:54.\n",
            "  Batch 44,400  of  1,563.    Elapsed: 0:08:56.\n",
            "  Batch 44,500  of  1,563.    Elapsed: 0:08:57.\n",
            "  Batch 44,600  of  1,563.    Elapsed: 0:08:58.\n",
            "  Batch 44,700  of  1,563.    Elapsed: 0:08:59.\n",
            "  Batch 44,800  of  1,563.    Elapsed: 0:09:00.\n",
            "  Batch 44,900  of  1,563.    Elapsed: 0:09:02.\n",
            "  Batch 45,000  of  1,563.    Elapsed: 0:09:03.\n",
            "  Batch 45,100  of  1,563.    Elapsed: 0:09:04.\n",
            "  Batch 45,200  of  1,563.    Elapsed: 0:09:05.\n",
            "  Batch 45,300  of  1,563.    Elapsed: 0:09:06.\n",
            "  Batch 45,400  of  1,563.    Elapsed: 0:09:08.\n",
            "  Batch 45,500  of  1,563.    Elapsed: 0:09:09.\n",
            "  Batch 45,600  of  1,563.    Elapsed: 0:09:10.\n",
            "  Batch 45,700  of  1,563.    Elapsed: 0:09:11.\n",
            "  Batch 45,800  of  1,563.    Elapsed: 0:09:12.\n",
            "  Batch 45,900  of  1,563.    Elapsed: 0:09:14.\n",
            "  Batch 46,000  of  1,563.    Elapsed: 0:09:15.\n",
            "  Batch 46,100  of  1,563.    Elapsed: 0:09:16.\n",
            "  Batch 46,200  of  1,563.    Elapsed: 0:09:17.\n",
            "  Batch 46,300  of  1,563.    Elapsed: 0:09:18.\n",
            "  Batch 46,400  of  1,563.    Elapsed: 0:09:20.\n",
            "  Batch 46,500  of  1,563.    Elapsed: 0:09:21.\n",
            "  Batch 46,600  of  1,563.    Elapsed: 0:09:22.\n",
            "  Batch 46,700  of  1,563.    Elapsed: 0:09:23.\n",
            "  Batch 46,800  of  1,563.    Elapsed: 0:09:24.\n",
            "  Batch 46,900  of  1,563.    Elapsed: 0:09:26.\n",
            "  Batch 47,000  of  1,563.    Elapsed: 0:09:27.\n",
            "  Batch 47,100  of  1,563.    Elapsed: 0:09:28.\n",
            "  Batch 47,200  of  1,563.    Elapsed: 0:09:29.\n",
            "  Batch 47,300  of  1,563.    Elapsed: 0:09:30.\n",
            "  Batch 47,400  of  1,563.    Elapsed: 0:09:32.\n",
            "  Batch 47,500  of  1,563.    Elapsed: 0:09:33.\n",
            "  Batch 47,600  of  1,563.    Elapsed: 0:09:34.\n",
            "  Batch 47,700  of  1,563.    Elapsed: 0:09:35.\n",
            "  Batch 47,800  of  1,563.    Elapsed: 0:09:37.\n",
            "  Batch 47,900  of  1,563.    Elapsed: 0:09:38.\n",
            "  Batch 48,000  of  1,563.    Elapsed: 0:09:39.\n",
            "  Batch 48,100  of  1,563.    Elapsed: 0:09:40.\n",
            "  Batch 48,200  of  1,563.    Elapsed: 0:09:41.\n",
            "  Batch 48,300  of  1,563.    Elapsed: 0:09:43.\n",
            "  Batch 48,400  of  1,563.    Elapsed: 0:09:44.\n",
            "  Batch 48,500  of  1,563.    Elapsed: 0:09:45.\n",
            "  Batch 48,600  of  1,563.    Elapsed: 0:09:46.\n",
            "  Batch 48,700  of  1,563.    Elapsed: 0:09:48.\n",
            "  Batch 48,800  of  1,563.    Elapsed: 0:09:49.\n",
            "  Batch 48,900  of  1,563.    Elapsed: 0:09:50.\n",
            "  Batch 49,000  of  1,563.    Elapsed: 0:09:51.\n",
            "  Batch 49,100  of  1,563.    Elapsed: 0:09:53.\n",
            "  Batch 49,200  of  1,563.    Elapsed: 0:09:54.\n",
            "  Batch 49,300  of  1,563.    Elapsed: 0:09:55.\n",
            "  Batch 49,400  of  1,563.    Elapsed: 0:09:56.\n",
            "  Batch 49,500  of  1,563.    Elapsed: 0:09:57.\n",
            "  Batch 49,600  of  1,563.    Elapsed: 0:09:59.\n",
            "  Batch 49,700  of  1,563.    Elapsed: 0:10:00.\n",
            "  Batch 49,800  of  1,563.    Elapsed: 0:10:01.\n",
            "  Batch 49,900  of  1,563.    Elapsed: 0:10:02.\n",
            "\n",
            "Test took: 0:10:03\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AXvRLrp88Uo"
      },
      "source": [
        "test_csv = test_result.to_csv('test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bANOBRz-ft7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "2143702f-b5b2-4d95-83d3-b2670fbef8b9"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('test.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_81e617bf-934e-46ad-b6f0-f7955d437ead\", \"test.csv\", 5291590)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}